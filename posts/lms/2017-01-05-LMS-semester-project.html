<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Staged meta-programming, new LMS frontend and computation graphs - Ruben Fiszel's website</title>
	<link rel="icon" type="image/png" href="../../images/lambda-xl.png">
	<link rel="stylesheet" type="text/css" href="../../css/syntax.css" />
	<link rel="stylesheet" type="text/css" href="../../sass/main.css" />
	<link type="text/css" href="../../css/font-awesome.min.css" rel="stylesheet">
	<link rel="stylesheet" href="../../css/mermaid.css">
	<link rel="stylesheet" href="../../fonts/Serif/cmun-serif.css" />
	<link href="http://fonts.googleapis.com/css?family=Droid+Serif" rel="stylesheet" type="text/css">
	<link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">
	<script type="text/javascript" async
		src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1//MathJax.js?config=TeX-AMS_CHTML"></script>
</head>

<body>
	<div id="header">
		<div id="logo">
			<img src="../../images/lambda.png" alt="Lambda">
			<a href="../../">Ruben Fiszel's website</a>
		</div>

		<div id="navigation">
			<a href="../../">Home</a>
			<a href="../../about.html">About</a>
			<a href="../../contact.html">Contact</a>
		</div>
		<div class="clear"></div>
	</div>

	<div id="content">
		<h1 class="post-title"> Staged meta-programming, new LMS frontend and computation graphs</h1>
		<h2 class="post-title"> </h2>

		<div class="info">
			Posted on January 5, 2017

			by Ruben Fiszel

		</div>
		<div class="post">
			<h2 id="note">Note</h2>
			<p>This is a web-formatted version of my semester project II at the <a href="http://lamp.epfl.ch/">LAMP</a>
				of EPFL under the supervision of <a href="http://lampwww.epfl.ch/~amin/cv/">Nada Amin</a> and <a
					href="http://lampwww.epfl.ch/~odersky/">Prof. Martin Odersky</a>. The code is available <a
					href="https://github.com/rubenfiszel/lms-clean/">here</a>.</p>
			<h2 id="abstract">Abstract</h2>
			<p>In this report, we explore staged meta-programming, in particular the LMS framework and the development
				of its new frontend whose aim is to ease the development of staged meta programs and their DSL libraries
				through, among others, shadowing of types. We also explore the usage of this new frontend for a
				particular case study Staged computation graphs with cycle, dimensions and topology checking at staging
				time. We observe a signigicant performance improvement at evaluation compared to a non-staged program.
			</p>
			<h1 id="introduction" class="unnumbered">Introduction</h1>
			<p>If programming is an art, then programming languages are the artitst’s brush. The tools are chosen
				according to individual preferences, but with memory, scaling and performance constraints in mind. One
				of those major constraints is efficiency. Efficiency is less crucial nowadays than it was back when
				computing power was expensive and scarce, but it is still a very desirable goal. Efficiency can be
				achieved by writing explicitly and very precisely each step of the program. To enable this, some
				programming languages are relatively close from the model of the hardware. Those programming languages
				are called “low-level”, because close from the machine and thus distant from the heights of abstraction.
				But as programs grow more complex, the need for abstraction does too.</p>
			<p>To raise abstraction power, expressive languages with complex compilers were made. Ironically, the first
				programming language, lambda-calculus, was the epitome of abstraction and thought of before the first
				very computer to execute it. Those languages, mostly from the functional programming world, help the
				user to express the intent rather than the steps, the “what” rather than the “how”. The compilers needed
				for them are heavy machineries that applies all sorts of optimizations before translating source code to
				machine language. The more abstract the language, the more gap there is to fill, and the more compilers
				have opportunity to optimize.</p>
			<p>Hence, in an ideal world, we can achieve <strong>abstraction without regret</strong>, writing very
				abstract programs compiled with optimal efficiency for any platform and any hardware. Unfortunately, we
				are not there yet, and expert implementers are still very much in need. So, should we just throw all our
				efforts into writing the ultimate compiler for the ultimate language ?</p>
			<p>Growing complexity in compiler is not the panacea. In a wide range of programs, compilers are limited by
				the lack of domain-specific knowledge. Indeed, constraining a program to one specific domain opens the
				door for a wide range of specific optimizations. Furthermore, code generation by “macro” is a common but
				rather poor way to enable the full extent of abstraction power brought by code generation.</p>
			<p>One solution to both issue could be to extend the compiler for each domain and having a very developped
				macro system. The other one, is to write specific domain-specific language in a staged environment. To
				avoid reinventing the wheel, embedded DSL is a nice compromise between specialized and general-purpose
				languages. It is this embedded DSL in staged meta-programming environment that is explored with LMS, a
				Scala library for runtime code generation. In the first part, we will study LMS and its related
				concepts. Then in the second part, we will cover the new frontend implementation that offers a new user
				frontend, more convenient for the end-user and with multiple benefits enabled by extended typeclass
				usage. We also cover a case study of LMS applied to the domain of computation graphs.</p>
			<h1 id="lms">LMS</h1>
			<p>Lightweight Modular Staging (LMS) is a Scala framework for runtime code generation. It has two main
				overlapping uses:</p>
			<ul>
				<li>As a meta-programming framework for writing staging compilers. A staging compiler can generate
					object programs from user meta-programs written in a subset of Scala with staging annotations
					enriched with DSL. An example of such meta-programs can be staged interpreters. As we will see
					later, staged interpreters are compilers themselves.</li>
				<li>As a Transpiler framework for writing optimised transpilers from programs written in a subset of
					Scala enriched with DSL. We will see that this case applies when the user programs are intended to
					use lifted types in lieu of common types.</li>
			</ul>
			<p>By “transpiler”, we mean that compared to a compiler, the generated output is a valid source code in a
				given programming language. It is optimized in the sense that the written transpiler does not only
				translate code from one language to another but will also be capable to applies some transformation to
				the internal representation of the user program before generating the output. Among those
				transformations, we can apply the usual compiler optimisations. We can also apply some more
				domain-specific transformations if needed. This enable to use Scala as an abstract unified source
				language to generate programs composed of various specialized languages and that target heterogenous
				hardware. This is the case of the framework Delite, written on top of LMS.</p>
			<p>Meta-programming is the art of writing computer programs that can handle other programs as data. Thus,
				they are able to reason about programs, which they are themselves, hence the name. In staged
				meta-programming, the goal is to generate new programs from annotated programs. Those annotations are
				called staged annotations. The program source is called the <strong>meta-program</strong>. The program
				being generated is the the <strong>object program</strong>. The generation can go through multiple
				stage. Each stage is another transformation that can leverage new informations to build the next
				program. LMS is heterogeneous: the meta-program and the object program can be written in different
				programming languages (e.g: generating C with formal proofs annotations as in lms-verify).</p>
			<h2 id="why-staging">Why staging</h2>
			<p>To see the benefits of a staged meta-program, we will start by an example where its benefits shine
				clearly: sparse vector multiplication.</p>
			<p>Assume that v1 and v2 are sparse vector of size N with K cells containing Integers:
				<code>N &gt;&gt; K</code>.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">val</span> v1: IndexedSeq[Int]
<span class="kw">val</span> v2: IndexedSeq[Int]
v1.<span class="fu">zip</span>(v2) map { <span class="kw">case</span> (x1, x2) =&gt; x1 * x2 } sum</code></pre>
			</div>
			<p>This works but it is terribly inefficient. What about all those 0-multiplications. Surely, we can
				something better. There is 3 cases:</p>
			<ol style="list-style-type: decimal">
				<li>v1 and v2 are both known at compile time</li>
				<li>v1 is known at compile time</li>
				<li>v1 and v2 are both only known at runtime</li>
			</ol>
			<p>In the two first case, staged meta-programming is able to generate efficient code that avoid the
				(<code>N [zip] + N [*]</code>) operations at runtime and reduce it to <code>K</code> operations (no more
				zip) and even 0 operations in the first case!</p>
			<p>How ? Well it is all about available information. We will start with the first case which is the simplest
				to understand: We know at staging time all the data and all the operations that are applied to the data.
				Instead of waiting for runtime to apply those operations, we can generate a new block that is strictly
				equivalent. We use the simple optimisations: <code>0*a = 0</code>, <code>0+a=a</code>,
				<code>(A) + (B) = (A+B)</code>, <code>(A) * (B) = (A*B)</code>. <code>()</code> is a fake notation for
				the purpose of explanation that surrounds integers whose values are known during staing.</p>
			<p>The generated code in the first can be reduced to:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">val</span> x0 = (C)
x0</code></pre>
			</div>
			<p>where <code>C</code> is a constant which value depend on <code>v1</code> and <code>v2</code>. During
				staging, the expression corresponding to x0 is reduced from a large tree of
				<code>[(D) * (E)] + ... + [(F) * (G)] = (I) + ... + (J) = (C)</code></p>
			<p>It is commonly called “constant folding”.</p>
			<p>In the second case, let us assume that <code>i1, i2, ..., i10</code> are the index of the non-zero value
				of v1. The code can be generated to this reduced form:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">val</span> x0 = <span class="fu">v1</span>(i0) * <span class="fu">v2</span>(i0)
<span class="kw">val</span> x1 = <span class="fu">v1</span>(i1) * <span class="fu">v2</span>(i1)
<span class="kw">val</span> x2 = x0 + x1
<span class="kw">val</span> x3 = <span class="fu">v1</span>(i2) * <span class="fu">v2</span>(i2)
<span class="kw">val</span> x4 = x3 + x2
...
<span class="kw">val</span> x12 = x11 + x10
x12</code></pre>
			</div>
			<p>In the third case, we can still gain efficiency by replacing some of the abstraction overhead from zip
				and sum into simple plain <code>+</code> and <code>*</code> operations.</p>
			<h2 id="staged-meta-programming">Staged meta-programming</h2>
			<p>In LMS, the meta-program is written in a subset of Scala. This subset is:</p>
			<ul>
				<li>every operations on any type that has a “lifted” implementation. Int/Float/Double/Array and more are
					already part of LMS (<em>batteries included</em>)</li>
				<li>if-then-else</li>
				<li>for-loop/while</li>
				<li>lambda-functions and named functions</li>
				<li>equalities</li>
			</ul>
			<p>We will see later what a lifted implementation is but for now let say that any type can be added to LMS
				as long as we write some appropriate implementations for it. Other projects like scala-native are
				focused only on LLVM generation but support the full Scala language.</p>
			<h2 id="staging">Staging</h2>
			<p>Staging is the operation that generates object programs (also referred as staged programs) from
				meta-programs. For instance, the usual final “pipeline” is to write a meta-program, stage it (this
				includes a compile-time and a run-time), then compile and run the object program.</p>
			<p>Staged annotations are used at staging time to give information about how we intend the object program to
				be built.</p>
			<p>In meta-programming, the staged annotations can usually take multiple forms:</p>
			<ul>
				<li>String (Yes, you read that right, the full program is written as a string!)</li>
				<li>Abstract-Data-Type (Add(Int(2), Int(3)))</li>
				<li>quasiquotes (Meta-OCaml)</li>
			</ul>
			<p>The LMS way is … neither. It is based on a virtualized extension of Scala, DSL whose operations on lifted
				types creates an expression tree by a deep reuse of the Scala evaluation order. Those combined achieve a
				transparent and convenient meta-programming environment for the user since, it is virtually no different
				from a non-staged program. We will analyse those components of LMS below.</p>
			<h3 id="lifted-types">Lifted types</h3>
			<p>A lifted type represent an inner type at the next future stage. For instance, the lifted type of an
				integer is a declaration that, once staged, this same value will represent an integer. So instead of
				manipulating an integer directly, you manipulate an “integer once staged”.</p>
			<p>Below are example of the difference between common types and lifted types. Although similar in form those
				programs are different in nature:</p>
			<p>This one is a standard program stating that a, b are integers and that c is their sum.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">val</span> a: Integer
<span class="kw">val</span> b: Integer
<span class="kw">val</span> c: Integer = a + b</code></pre>
			</div>
			<p>This one is a meta-program stating that a, b will be integers in the object program and that c in the
				object program should represent their sum.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">val</span> a: LiftedInteger
<span class="kw">val</span> b: LiftedInteger
<span class="kw">val</span> c: LiftedInger a + b</code></pre>
			</div>
			<p>Notice that even though we use the same operator +, we necessary have to redefine it for LiftedInteger.
				But instead of actually summing integers, this new + operator will build the right Internal
				Representation (IR) for this object-program operation.</p>
			<h3 id="internal-representation-and-the-exp-tree">Internal representation and the Exp tree</h3>
			<p>In order to manipulate meta-programs, it has to first convert the source code of a meta-program into a
				more convenient representation, easier to manipulate. This representation is called Internal
				Representation (IR). The IR of LMS is based on typed expression trees and single static assignments
				(SSA). This representation is a «sea of nodes» representation.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">trait</span> Exp[+T]
<span class="co">// Constant expression of type T</span>
<span class="kw">case</span> <span class="kw">class</span> Const[T](x: T) <span class="kw">extends</span> Exp[T]
<span class="co">// Symbol referencing a definition of type T</span>
<span class="kw">case</span> <span class="kw">class</span> Sym[T](id: Int) <span class="kw">extends</span> Exp[T]
<span class="co">// Composite node that is defined by a library or DSL author</span>
<span class="kw">trait</span> Def[+T]
<span class="co">// Statement in the IR</span>
<span class="kw">case</span> <span class="kw">class</span> TP[+T](sym: Sym[T], rhs: Def[T])</code></pre>
			</div>
			<p>An assignment links a symbol to a definition. A definition is a composite node that represents an
				operation on other expressions (e.g: <code>Minus(e1:Exp[Int], e2:Exp[Int]) extends Def[Int])</code>) and
				defines the result type. The expression tree in itself is a typed tree made of only two leaves:
				Constants and Symbols: «Wait, where are the nodes ?». The nodes are in fact the symbols, or more
				precisely, the composite node Def that the symbol represents (As stated by a <code>TP</code>). Constants
				are meta-programs values (e.g: a meta-program <code>val a:LiftedInteger = 2</code> is represented in the
				IR as this constant expression: <code>Const(2)</code>.</p>
			<p>By using Scala pattern extractors and implicit conversions, we can reconstruct and manipulate this tree
				as if it was made only of <code>Def</code> and <code>Const</code> which is more natural.</p>
			<p>For instance:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">val</span> a: Integer = ...
<span class="kw">val</span> b: Integer = ...
cal c: Integer = (a + b) - (a * b)</code></pre>
			</div>
			<p>is represented as:</p>
			<div class="sourceCode">
				<pre
					class="sourceCode scala"><code class="sourceCode scala"><span class="fu">TP</span>(<span class="fu">Sym</span>(<span class="dv">0</span>), ...)
<span class="fu">TP</span>(<span class="fu">Sym</span>(<span class="dv">1</span>), ...)
<span class="fu">TP</span>(<span class="fu">Sym</span>(<span class="dv">2</span>), <span class="fu">Add</span>(<span class="fu">Sym</span>(<span class="dv">0</span>), <span class="fu">Sym</span>(<span class="dv">1</span>)))
<span class="fu">TP</span>(<span class="fu">Sym</span>(<span class="dv">3</span>), <span class="fu">Times</span>(<span class="fu">Sym</span>(<span class="dv">0</span>), <span class="fu">Sym</span>(<span class="dv">1</span>)))
<span class="fu">TP</span>(<span class="fu">Sym</span>(<span class="dv">4</span>), <span class="fu">Minus</span>(<span class="fu">Sym</span>(<span class="dv">2</span>), <span class="fu">Sym</span>(<span class="dv">3</span>)))</code></pre>
			</div>
			<p>But can be manipulated as:</p>
			<div class="sourceCode">
				<pre
					class="sourceCode scala"><code class="sourceCode scala"><span class="fu">Minus</span>(<span class="fu">Add</span>(a, b), <span class="fu">Times</span>(a, b))</code></pre>
			</div>
			<p>We will not describe further the IR since this project focus on the frontend. It will be clearer later
				what separates the backend from the frontend. But a simple informal definition is that the subset of
				Scala that is available to the user to write meta-programs is the in scope of the frontend. This
				includes the lifted types interface and the building of the IR as a tree solely made of Def hybrid
				nodes. On the other hand, the IR representation as a sea of nodes, the IR manipulation such as with
				transformers and traversals and code generation are in the scope of the backend.</p>
			<h3 id="lifted-types-and-dsl-operations">Lifted types and DSL operations</h3>
			<p>The previous frontend of LMS was representing lifted types as wrapped in a Rep monad.
				<code>LiftedInteger</code> would be written as <code>Rep[Int]</code>. The idea is that if A is the
				expected type in the object-program then we manipulate its Rep-resentation. This monad was the staging
				annotation.</p>
			<p>The way to define operations on DSL was to define operators in scope that would manipulate the given Rep.
			</p>
			<p>For instance, the DSL provided operations on Integers such as</p>
			<div class="sourceCode">
				<pre
					class="sourceCode scala"><code class="sourceCode scala"><span class="kw">def</span> infix_+(e1: Rep[Int], e2:Rep[Int])</code></pre>
			</div>
			<p>So as long as the corresponding methods or operators were in scope, the user was able to manipulate
				conveniently <code>Rep[A]</code> as if they were <code>A</code>.</p>
			<h3 id="lift">Lift</h3>
			<p>The LMS solution to use Literals and other explicitly declared object is to use global conversion methods
				that know how to convert some present value to staged value. Their role is to convert <code>A</code>
				into <code>Rep[A]</code>. Those conversions are implicit and enable to write such declaration
				<code>val a: Rep[Int] = 2</code>. What is really happening is the Scala solve the implicit lift
				conversion and it becomes <code>val a: Rep[Int] = lift(2)(intLift)</code> with <code>intLift</code>
				being an instance of <code>Lift[Int,Rep[Int]]</code>. The sole purpose of <code>Lift</code> instance is
				to lift values into lifted types.</p>
			<h2 id="scala-virtualization">Scala virtualization</h2>
			<p>In order to enable the if-then-else/loops and other control, we use a modified version of the Scala
				language: scala-virtualized. Scala-virtualized enable to overload the controls as common functions: e.g:
				<code>if (t1) t1 else t2</code> becomes <code>__ifThenElse(t1, t2, t3)</code>. We can use this
				overloading to extend the controls to lifted type.</p>
			<h2 id="smart-constructors">Smart constructors</h2>
			<p>Smart constructors are optimised constructors of composite def that can apply optimisations based solely
				on the arguments of the constructor. For instance, for the constructor of IntTimes which represents
				multiplication of integer we can potentially apply some early reductions.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">  <span class="kw">override</span> <span class="kw">def</span> <span class="fu">int_times</span>(e1: Exp[scala.<span class="fu">Int</span>], e2: Exp[scala.<span class="fu">Int</span>])
  : Exp[scala.<span class="fu">Int</span>] = (e1, e2) <span class="kw">match</span> {
    <span class="kw">case</span> (<span class="fu">Const</span>(<span class="dv">0</span>), r) =&gt; <span class="fu">Const</span>(<span class="dv">0</span>)
    <span class="kw">case</span> (l, <span class="fu">Const</span>(<span class="dv">0</span>)) =&gt; <span class="fu">Const</span>(<span class="dv">0</span>)
    <span class="kw">case</span> (<span class="fu">Const</span>(<span class="dv">1</span>), r) =&gt; r
    <span class="kw">case</span> (l, <span class="fu">Const</span>(<span class="dv">1</span>)) =&gt; l
    <span class="kw">case</span> (<span class="fu">Const</span>(x), <span class="fu">Const</span>(y)) =&gt; <span class="fu">Const</span>(x*y)
    <span class="kw">case</span> _ =&gt; <span class="fu">IntTimes</span>(e1, e2)            
  }</code></pre>
			</div>
			<h3 id="deep-reuse-of-the-evaluation-order">Deep reuse of the evaluation order</h3>
			<p>Deep reuse of the embedding language order is a simple concept. The embedding language is Scala. The Exp
				tree construction is dependant on the order of evaluation of the operations applied to the lifted types.
				That order is the one of the normal method order of Scala.</p>
			<p>For instance:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">val</span> a: Rep[Int] = <span class="dv">2</span> <span class="co">//Const(2)</span>
<span class="kw">val</span> b: Rep[Int] = <span class="dv">3</span> <span class="co">//Const(3)</span>

<span class="co">//IntAdd(Const(2), Const(3))</span>
<span class="kw">val</span> c: Rep[Int] = <span class="dv">2</span> + <span class="dv">3</span> 
<span class="co">//IntAdd(IntAdd(Const(2), Const(3)), Const(4))</span>
<span class="kw">val</span> d: Rep[Int] = c + <span class="dv">4</span> </code></pre>
			</div>
			<p>Contrary to plain Scala, <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code> here are not
				“simple” values. They are each a representation of a tree of <code>Exp</code>. <code>a</code> and
				<code>b</code> are trivial trees of one node: A constant leaf. However, <code>c</code> and
				<code>d</code> start to becomes more complex. The actual content of each tree depend of the evaluation
				order of the frontend operations by Scala. At code generation, the tree order is conserved through let
				bindings.</p>
			<h2 id="transformers">Transformers</h2>
			<p>Nevertheless, between the tree construction and code generation, some transformations might have built a
				new IR from the current IR. Common Subexpression Elimination, Code motion, Loop Unrolling, Dead Code
				Elimination, Loop Fusion and more are among such potential transformations. Transformations are applied
				until a fixed point is achieved. Transformations are written in LMS as subtype of
				<code>Transformer</code>.</p>
			<h2 id="dsl-as-libraries">DSL as libraries</h2>
			<p>LMS enables meta-programming and doesn’t necessarily require the use of DSL. Nevertheless, a powerful way
				to use LMS is to provide DSL written on top of LMS that includes all the necessary lifted types and
				transformers to build domain-specific application from. The <code>common/</code> part of LMS are a
				provided batterie of lifted types and transformers that should be needed in most cases. It includes,
				if-then-else, primitive types, and useful transformers such as CSE and code motion. On top of that,
				libraries author can add their own lifted types and transformer to provide a new « flavour » of LMS that
				form a DSL.</p>
			<h2 id="delite">Delite</h2>
			<p>Delite is a research project from Stanford University’s Pervasive Parallelism Laboratory (PPL). Delite is
				built on top of LMS and could be seen as an alternative or supplement of <code>common/</code> targeted
				for high-performance parallel DSL. Furhermore, Delite includes the Delite Execution Graph whose purpose
				to orchestrate the application written potentially as multiple object programs (e.g one part in CUDA,
				one part in C and the last part in Scala). Last but not least, the Delite team have created Forge whose
				purpose is to generate DSL as libraries for LMS from a unified specification language that avoids any
				boilerplate.</p>
			<h2 id="users">Users</h2>
			<p>LMS is designed as a framework to write meta-programs. Users are the final writers of those meta-programs
				using a DSL as a library on top of LMS or even just bare LMS with <code>common/</code>.</p>
			<div class="figure">
				<img src="LMS-org.png" alt="LMS Org" />
				<p class="caption">LMS Org</p>
			</div>
			<h1 id="the-new-frontend">The new frontend</h1>
			<p>LMS is reimplemented with a new frontend. One goal of this reimplementation is to achieve sufficient
				feature parity with the previous version of LMS to enable to implement meta-programs in the computation
				graph domain as explained further in part 3.</p>
			<p>LMS is mainly split into <code>internal/</code> and <code>common/</code>:</p>
			<ul>
				<li><code>common/</code> includes all the commodity that should be common to all DSL. For instance,
					primitive types (<code>Int</code>, <code>Double</code>, <code>String</code>, etc …), primitive
					containers (<code>List</code>, <code>Array</code>) or control blocks like if-then-else. Common also
					includes a set of transformer for optimising IR. Those transformations include the usual compiler
					optimisations such as Common Subexpression Elimination, Code motion, Loop Unrolling, Dead Code
					Elimination and Loop Fusion.</li>
				<li><code>internal/</code> contains all the code related to the internal components of LMS such as the
					definition of <code>Expressions</code> or <code>Transformer</code> or <code>Codegen</code> etc …
				</li>
			</ul>
			<p>The new frontend change the type of lifted type from Rep monads to a Rep context bound. This modifcation
				implies a conversion of most of <code>common/</code> and <code>internal/</code>. The first part of this
				semester project was to apply this adaptation to both <code>common/</code> and <code>internal/</code>,
				and to take advantage of the rewriting to apply some new ideas and concepts to LMS. These new ideas were
				thought of and discussed with the collaboration of the Delite team and the LMS author, Tiark Rompf.
				Indeed, the modifications were far from mechanical, and leveraging the new nature of lifted types, some
				core parts of LMS have been rethought.</p>
			<h2 id="the-typeclass-pattern">The typeclass pattern</h2>
			<p>A context bound in Scala is used in the typeclass pattern.</p>
			<p>The typeclass patterns is an alternative to inheritance to write polymorphic code knowing a given
				interface. With subtyping, we declare that if A is a child of B (A &lt;: B), then any instance of A can
				be treated as B (A is a B). Then we can write code that is polymorphic for any child class thanks to the
				common interface of B.</p>
			<p>With the typeclass pattern, we declare that as long as there exists a typeclass instance for the right
				parametrized type, we can write our polymorphic code.</p>
			<p>For instance, let visit the case of abstracting that some types like <code>Int</code> and
				<code>Float</code> are numeric and share some methods like <code>*</code> and <code>+</code>.</p>
			<p>The OO way is through subtyping:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="co">//inheritance</span>
<span class="kw">trait</span> Num[A] {	
	<span class="kw">def</span> *(y: A): A
	...
}

<span class="kw">class</span> Int <span class="kw">extends</span> Num[Int]{
	<span class="kw">def</span> *(y: Int): Int = ...
}

<span class="kw">def</span> square[A](x: Num[A]) = x*x</code></pre>
			</div>
			<p>The typeclass pattern is through typeclass instances:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="co">//typeclass pattern</span>
<span class="kw">trait</span> Num[A] {	
	<span class="kw">def</span> <span class="fu">times</span>(x: A, y: A): A
	...
}

<span class="kw">class</span> Int {
	<span class="kw">def</span> *(y:Int): Int = ...
	...
}

<span class="kw">implicit</span> <span class="kw">object</span> numInt <span class="kw">extends</span> Num[Int] {
	<span class="kw">def</span> <span class="fu">times</span>(x: Int, y: Int) = x*y
}

<span class="kw">def</span> square[A: Num](x: A) = {
	<span class="kw">val</span> num = implicitly[Num[A]]
	num.<span class="fu">times</span>(x, x)
}</code></pre>
			</div>
			<p>The idea behind the new frontend is to use that typeclass pattern as staging annotation instead of the
				Rep monad.</p>
			<div class="figure">
				<img src="new-LMS-org.png" alt="New LMS Org" />
				<p class="caption">New LMS Org</p>
			</div>
			<p>In the previous LMS, we manipulated lifted types <code>Rep[A]</code> and defined specific functions in
				scope for that particular <code>Rep[A]</code>.</p>
			<p>In the new LMS, we manipulate <code>dsl.A</code> that have Rep typeclass instances defined in scope.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">
<span class="kw">trait</span> Rep[T] {
	<span class="kw">type</span> Internal
	<span class="kw">def</span> <span class="fu">from</span>(e:Exp[Internal]): T
	<span class="kw">def</span> <span class="fu">to</span>(t: T): Exp[Internal]
}

<span class="kw">case</span> <span class="kw">class</span> Int(e: Exp[scala.<span class="fu">Int</span>]) {
	<span class="kw">def</span> *(y: Int) = <span class="fu">IntTimes</span>(e, y.<span class="fu">e</span>)
}

<span class="kw">implicit</span> <span class="kw">object</span> intRep <span class="kw">extends</span> Rep[Int] {
	<span class="kw">type</span> Internal = scala.<span class="fu">Int</span>
	<span class="kw">def</span> <span class="fu">from</span>(e:Exp[Internal]) = Int(e)
	<span class="kw">def</span> <span class="fu">to</span>(t: Int) = t.<span class="fu">e</span>
}</code></pre>
			</div>
			<p>Then we can write functions in this manner.</p>
			<div class="sourceCode">
				<pre
					class="sourceCode scala"><code class="sourceCode scala"><span class="kw">def</span> ifThenElse[A: Rep](a: dsl.<span class="fu">Boolean</span>, b: A, c: A): A</code></pre>
			</div>
			<p>Note that the signature of ifThenElse is rather elegant because except for the Rep context bound, it
				looks exactly like the expected ifThenElse signature.</p>
			<h2 id="type-shadowing">Type shadowing</h2>
			<p>The convenient benefit of using dsl.A is that once the dsl is imported, we can shadow the type A by
				dsl.A. For instance, dsl.Int shadows scala.Int. This is especially useful to write meta-programs for
				which the lifted type of A, dsl.A, is the most common meaning of the type A.</p>
			<p>For instance, with dsl.Int in scope we can write:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="co">//Int here is in fact dsl.Int. </span>
<span class="co">//Return type will be inferred to Int as well </span>
<span class="kw">def</span> <span class="fu">square</span>(x: Int) = x*x 

<span class="co">//a here is a scala.Int</span>
<span class="kw">val</span> a = <span class="dv">2</span>

<span class="co">//but it is implicitely lifted before</span>
<span class="co">//being applied to square</span>
<span class="kw">val</span> b = <span class="fu">square</span>(a)</code></pre>
			</div>
			<p>which will result in a meta-program! The usage of lifted types is painless here.</p>
			<h2 id="typeclass-overloading">Typeclass overloading</h2>
			<p>One of the issue encountered with the new frontend of LMS is «typeclass overloading». In the previous
				LMS, equals could be defined in such way:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">
	<span class="kw">def</span> __equal[A, B](a: Rep[A], b:Rep[B]): Rep[Boolean]
	<span class="kw">def</span> __equal[A, B](a: Rep[A], b:B): Rep[Boolean]	
	<span class="kw">def</span> __equal[A, B](a: A, b:Rep[B]): Rep[Boolean]		
	<span class="kw">def</span> __equal[A, B](a: A, b:B): Boolean
	</code></pre>
			</div>
			<p>The Scala choose the right dispatch based on the most specialized definition of __equal. Note that
				<code>def __equal[A, B](a: A, b:B)</code> is a more general function than all above but only gets
				triggered if none of the above case triggers.</p>
			<p>Now with the typeclass pattern we could attempt such rewrite:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">
	<span class="kw">def</span> __equal[A:Rep, B:Rep](a: A, b:B): Boolean
	<span class="kw">def</span> __equal[A:Rep, B](a: A, b:B): Boolean
	<span class="kw">def</span> __equal[A, B:Rep](a: A, b:B): Boolean
	<span class="kw">def</span> __equal[A, B](a: A, b:B): scala.<span class="fu">Boolean</span>
	</code></pre>
			</div>
			<p>The issue is that context bound are only syntactic sugar and those functions are eventually desugared
				into:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">
	<span class="kw">def</span> __equal[A, B](a: A, b:B)
	(<span class="kw">implicit</span> repA: Rep[A], <span class="kw">implicit</span> repB: Rep[B]): Boolean
	<span class="kw">def</span> __equal[A, B](a: A, b:B)(<span class="kw">implicit</span> repA: Rep[A]): Boolean
	<span class="kw">def</span> __equal[A, B](a: A, b:B)(<span class="kw">implicit</span> repB: Rep[B]): Boolean
	<span class="kw">def</span> __equal[A, B](a: A, b:B): scala.<span class="fu">Boolean</span>
	</code></pre>
			</div>
			<p>The issue is that in this curried form, none of the first three definitions of __equal are more
				specialized than the last one. Hence, it is impossible to overload equal in this manner.</p>
			<h2 id="primitives-types">Primitives types</h2>
			<p>The new LMS frontend required to adapt the whole <code>internal/</code> to the new typeclass pattern but
				it also required to write primitive types and collections in a modified manner. We implemented the
				primitive types: <code>Int</code>, <code>Float</code>, <code>Double</code>, <code>Long</code> as well as
				<code>String</code>, <code>Boolean</code> and the collections <code>Array</code>, <code>Matrix</code>
				and <code>List</code>. We also implemented staged lambda functions, staged named functions, staged
				if-then-else blocks.</p>
			<p>Lifted types are organized in this manner for a type <code>A</code>.</p>
			<ul>
				<li><code>trait AOps[A]</code> defines the expected interface of A</li>
			</ul>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">trait</span> IntOps[A] {
	<span class="kw">def</span> +(y: A): A
}</code></pre>
			</div>
			<ul>
				<li><code>As</code> contains all the frontend interface</li>
			</ul>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">trait</span> Ints <span class="kw">extends</span> Base {

  <span class="kw">type</span> Int &lt;: IntOps[Int]

  <span class="kw">implicit</span> <span class="kw">def</span> intRep: Rep[Int] { <span class="kw">type</span> Internal = scala.<span class="fu">Int</span> }
  <span class="kw">implicit</span> <span class="kw">def</span> intLift: Lift[scala.<span class="fu">Int</span>,Int]

}</code></pre>
			</div>
			<ul>
				<li><code>AsExp</code> contains the Exp representation of <code>A</code></li>
			</ul>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">trait</span> IntsExp <span class="kw">extends</span> BaseExp <span class="kw">with</span> Ints {

  <span class="kw">case</span> <span class="kw">class</span> <span class="fu">IntPlus</span>(e1: Exp[scala.<span class="fu">Int</span>], e2: Exp[scala.<span class="fu">Int</span>])
  <span class="kw">extends</span> IntDef[scala.<span class="fu">Int</span>]
  
  <span class="kw">case</span> <span class="kw">class</span> Int(e: Exp[scala.<span class="fu">Int</span>])
  <span class="kw">extends</span> IntOps[Int] <span class="kw">with</span> Expressable[scala.<span class="fu">Int</span>] {
    <span class="kw">def</span> +(y: Int) = Int(<span class="fu">int_plus</span>(e, y.<span class="fu">e</span>))
  }
  
  <span class="kw">implicit</span> <span class="kw">val</span> intRep: Rep[Int] { <span class="kw">type</span> Internal = scala.<span class="fu">Int</span> } = ...
  <span class="kw">implicit</span> <span class="kw">val</span> intLift: Lift[scala.<span class="fu">Int</span>,Int] = ...
  
  <span class="kw">protected</span> <span class="kw">def</span> <span class="fu">int_plus</span>(e1: Exp[scala.<span class="fu">Int</span>], e2: Exp[scala.<span class="fu">Int</span>]):
  Exp[scala.<span class="fu">Int</span>]
}</code></pre>
			</div>
			<ul>
				<li><code>AsImpl</code> contains the basic constructors.</li>
			</ul>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">trait</span> IntsImpl <span class="kw">extends</span> IntsExp {
  <span class="kw">protected</span> <span class="kw">def</span> <span class="fu">int_plus</span>(e1: Exp[scala.<span class="fu">Int</span>], e2: Exp[scala.<span class="fu">Int</span>])
  = <span class="fu">IntPlus</span>(e1, e2)  
}</code></pre>
			</div>
			<ul>
				<li><code>AsOptImpl</code> contains the smart constructors.</li>
			</ul>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">trait</span> IntsOptImpl <span class="kw">extends</span> IntsImpl <span class="kw">with</span> EffectExp {
  <span class="kw">override</span> <span class="kw">def</span> <span class="fu">int_plus</span>(e1: Exp[scala.<span class="fu">Int</span>], e2: Exp[scala.<span class="fu">Int</span>]):
  Exp[scala.<span class="fu">Int</span>] = (e1, e2) <span class="kw">match</span> {
    <span class="kw">case</span> (<span class="fu">Const</span>(<span class="dv">0</span>), r) =&gt; r
    <span class="kw">case</span> (l, <span class="fu">Const</span>(<span class="dv">0</span>)) =&gt; l
    <span class="kw">case</span> (<span class="fu">Const</span>(x), <span class="fu">Const</span>(y)) =&gt; <span class="fu">Const</span>(x+y)
    <span class="kw">case</span> _ =&gt; <span class="kw">super</span>.<span class="fu">int_plus</span>(e1, e2)
  }
}</code></pre>
			</div>
			<h2 id="collections">Collections</h2>
			<p>Containers like <code>List</code> force us to decide between multiple potential and equally valid choice.
				The first of them is either their IR is a list of expression or if they are an expression of a list
				(<code>Exp[scala.List[A]]</code> vs <code>scala.List[Exp[A]]</code>). We decide for the former as the
				latter can be manipulated directly as <code>scala.List[A]</code> with <code>A</code> being a lifted type
				and does not require a lifted List type.</p>
			<p>The second issue is the multiplicity of the Lift case. Given that <code>Lift[B,A]</code> is in scope:</p>
			<ul>
				<li><code>scala.List[A]</code> should be able to lift to <code>dsl.List[A]</code></li>
				<li><code>dsl.List[B]</code> should be able to lift to <code>dsl.List[A]</code></li>
				<li><code>scala.List[A]</code> should be able lift to <code>scala.List[A]</code> or
					<code>dsl.List[A]</code></li>
			</ul>
			<p>We solve this issue by defining two lifts instead of one:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">  <span class="kw">implicit</span> <span class="kw">def</span> listLift[U, T](<span class="kw">implicit</span> tp: Rep[T], lift: Lift[U, T])
  : Lift[scala.<span class="fu">List</span>[U], List[T]]
  <span class="kw">implicit</span> <span class="kw">def</span> listLiftIdent[T](<span class="kw">implicit</span> tp: Rep[T]):
  Lift[scala.<span class="fu">List</span>[T], List[T]]</code></pre>
			</div>
			<p>The third issue is the choice to integrate the size of the List in its representation as a present time
				value (<code>scala.Int</code>), as a future time value (<code>dsl.Int</code>) or to not integrate it.
				The size is required for safety of some operations like apply and some other delicate cases. The choice
				was made to not integrate it and to let the user use a composite type if needed that include the size
				representation. Hence, some methods in the interface <code>ListOps</code> take the size as a
				<code>scala.Int</code> parameter.</p>
			<h2 id="functions">Functions</h2>
			<p>The new frontend enables an elegant signature for lifted functions which have seen a significative
				implementation change.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">  <span class="kw">implicit</span> <span class="kw">def</span> fun[A:Rep, B:Rep](f: A =&gt; B): Lambda[A,B]

  <span class="kw">type</span> Lambda[A,B] &lt;: A =&gt; B

  <span class="kw">implicit</span> <span class="kw">def</span> lambdaRep[A:Rep, B:Rep]: Rep[Lambda[A,B]]</code></pre>
			</div>
			<p>As we can see, from the function whose type is <code>A =&gt; B</code>, the lifted function is also a
				subtype of <code>A =&gt; B</code>.</p>
			<p>The way this is implemented is that when a function is applied for the first time, a representation of a
				named function is lazily generated and this application and all the futures ones are applied to this new
				named function.</p>
			<p>It is not necessary to lift a function and in most case, a simple inlining of the function body is enough
				which is what happen if the function is not lifted. Using an <code>implicit def fun</code> enables the
				automatic lifting of functions when needed ,but this might need to be removed in the future if the
				behavior reveals to be too unpredictable (since both the lifted and non-lifted type are subtype of
				<code>A =&gt; B</code>. Since lifted functions have <code>Rep</code> typeclass instances, they can be
				handled as “first class members” of other controls like if-then-else (and used as parameters and return
				type of all lifted controls).</p>
			<h1 id="computation-graph">Computation Graph</h1>
			<p>Computation graphs are directed graphs made of nodes that represent a computation. It is an abstract
				model that can generalize many functions. It is very common in distributed computing and it is how most
				deep learning (TensorFlow, Deeplearning4j) represents their neural networks models.</p>
			<div class="figure">
				<img src="comp-graph.png" alt="Example of a simple arithmethic computation graph" style="width:70.0%" />
				<p class="caption">Example of a simple arithmethic computation graph</p>
			</div>
			<p>Each node has 0 or more inputs and 0 or n outputs and 1 operation. Having 0 inputs is the special case of
				Input nodes and having 0 output is the special case of output nodes. The input nodes form the input
				layer. The output nodes form the output layer. We will only consider feedforward computation graphs
				without any cycles. An example of a node can be the Add node. It takes two entry and output their sum.
			</p>
			<p>The benefits of staging for Computation Graph is that there it would be advantageous to separate the
				construction of the graph and the execution of computation on this graph. Indeed, it is possible to
				check some properties on the computation graph that ensure that the graph has proper form. Furthermore,
				it is possible to apply transformation to the graph such as computing the gradient of the function
				represented by the graph. Last but not least, computation graph are abstractions that are convenient to
				build, conceptualize and handle but not very efficient because of the level of abstraction. Fortunately,
				after staging unnecessary indirections are removed and the whole function is linearised into the bare
				required operations.</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala"><span class="kw">trait</span> Graphs {

  <span class="kw">type</span> Data
  <span class="kw">type</span> Input = List[Data]
  <span class="kw">type</span> Output = Data
  <span class="kw">type</span> G &lt;: Graph 
  <span class="kw">type</span> N &lt;: Node
  
  <span class="kw">trait</span> Node { 
      <span class="kw">def</span> <span class="fu">output</span>(input: Input): Output 
  }
	

  ...

  <span class="kw">trait</span> Graph {

    <span class="co">//check if there is cycle in the graph</span>
    <span class="fu">checkCycle</span>()
    <span class="kw">def</span> inputSize: Int
	<span class="kw">type</span> R = (N, List[String])  	
    <span class="kw">def</span> nodes: Map[String, R]
    <span class="kw">def</span> <span class="fu">apply</span>(input: List[Data]) = { ... }
    <span class="kw">def</span> <span class="fu">checkCycle</span>() = { ...  }
    <span class="kw">def</span> <span class="fu">forward</span>(input: List[Data]): (Data, Map[String, Data]) = { ... }  
  
}


<span class="kw">trait</span> DerivableGraphs <span class="kw">extends</span> Graphs {

  <span class="kw">type</span> Data &lt;: AddTimeAble[Data]
  <span class="kw">type</span> Derivatives = List[Data]
  <span class="kw">type</span> N = DerivableNode
  <span class="kw">type</span> G = DerivableGraph
  ...
}
</code></pre>
			</div>
			<p>One of the clear benefits of using types as staged annotations is the ability to share codes between non
				staged programs and meta-programs. Indeed, the graph can set the type of data it manipulates as an
				abstract type member. Then depending on the type of graph and the type of nodes the graph may contain,
				this type can be upper bounded by the appropriate interface.</p>
			<p>Below the common forward evaluation of the graph implemented using memoization and recursion:</p>
			<div class="sourceCode">
				<pre class="sourceCode scala"><code class="sourceCode scala">    <span class="kw">def</span> <span class="fu">forward</span>(input: IndexedSeq[Data], dbg:Boolean = <span class="kw">false</span>) = {

      <span class="co">//init datas with provided input as input Node</span>
      <span class="kw">var</span> datas: Map[String, Data] =
        input.<span class="fu">zipWithIndex</span> 
			map { <span class="kw">case</span> (data, ind) =&gt; (<span class="st">&quot;IN&quot;</span>+(ind<span class="dv">+1</span>), data) } toMap

      <span class="kw">def</span> <span class="fu">output</span>(s: String): Data = {
        <span class="kw">val</span> (n, inp) = <span class="fu">nodes</span>(s)
        <span class="kw">if</span> (datas.<span class="fu">contains</span>(s)) 
          <span class="fu">datas</span>(s)
        <span class="kw">else</span> {
          <span class="kw">val</span> l = inp.<span class="fu">map</span>(output)
          <span class="kw">val</span> r = n.<span class="fu">output</span>(l)
          datas += ((s, r))
          r
        }
      }

      <span class="fu">output</span>(<span class="st">&quot;OUT&quot;</span>)

    }</code></pre>
			</div>
			<p><code>AddTimeAble[Data]</code> guarantees that Data has the operations <code>+</code> and <code>*</code>
				necessary for derivations.</p>
			<p>Here Data can be either <code>dsl.Int</code> for a staged computation graph or else a simple
				<code>scala.Int</code> (or at least a wrapper that implements AddTimeAble)</p>
			<h2 id="cycle-check">Cycle check</h2>
			<p>A staged computation graph builds the graph during staging. This means that all the verification that
				should happen during the building of the graph can happen during staging. This adds additional
				guarantees at runtime, here that our staged computation graph does not contain any cycle.</p>
			<h2 id="arithmetic">Arithmetic</h2>
			<p>We implement a graph with each node being a basic arithmetic operation (+,*,-,%,min,max) and a data type
				that is upper bounded by a basic arithmetic operation interface such that Int, Double and Float
				implement it. Those kinds of computation graph are a good sanity check as well as a clear example of the
				abstraction brought by a computation graph. We will use those arithmetic graphs to do benchmarking of
				their evaluation time performance as a staged meta-program and as a normal program. We do not take into
				account the efficiency of building those graphs and of the safety checks (like cycle check) because we
				want to measure efficiency in a “build once, evaluate often” context. We also add Constant Nodes that
				represent some fixed weights inside the graph such that some constant folding might happen. Those
				constant nodes are a decent way to represent fixed weights in a graph.</p>
			<h3 id="benchmark">Benchmark</h3>
			<p>For benchmarking purposes, we will randomly generate 2000 nodes big graphs. The graphs are build in a way
				that they stay balanced: each node is at most input of only 1 more node than any other node. We use Int
				as the Data type.</p>
			<p>We compare the non-staged computation graph to a meta-program that benefits from the optimised
				implementation of lifted Int. The optimised implementation of lifted Int differs from the non optimised
				optimisation of lift Int by smart-constructors that can optimize some operations such as multiplications
				with 0 or 1, or addition with 0 or binary operations on constants (Constant folding).</p>
			<p>We build 100 different graph and average the evaluation time to achieve meaningful results. Benchmarks
				are run on a thinkpad t440s:</p>
			<p>Average evaluation time:</p>
			<ul>
				<li>non-staged program: 2156 microseconds</li>
				<li>staged program: 171 microseconds.</li>
			</ul>
			<div class="figure">
				<img src="perf.png" alt="Performance chart" style="width:80.0%" />
				<p class="caption">Performance chart</p>
			</div>
			<h2 id="derivable-graphs">Derivable Graphs</h2>
			<p>We also implement backpropagation in both meta-programs and common programs. Backpropagation is an
				algorithm that enable fast computation of all partial derivatives in a computation graph with respect to
				the weights or in our case to the input nodes. Our backpropagation algorithm is common for both lifted
				and non-lifted types thanks to a <code>AddTimeAble</code> interface (derivability need at least
				<code>+</code> and <code>*</code> to be defined). This shows the flexibility of LMS.</p>
			<div class="figure">
				<img src="tree-backprop.png"
					alt="Example of a simple arithmethic computation graph with backpropagation" style="width:70.0%" />
				<p class="caption">Example of a simple arithmethic computation graph with backpropagation</p>
			</div>
			<h2 id="matrix-graphs">Matrix Graphs</h2>
			<p>Last but not least, we implement computation graphs able to handle Matrix as Data. Matrix as data is
				common in computation graph of neural networks and machine learning models. One interesting feature that
				we can have is to check the correct dimensions of the matrix between nodes during staging. For instance,
				the multiplication node is valid only if its input are of size <code>AxB</code> and <code>BxC</code>.
				This can be problematic if only checked at runtime but fortunately, in a staged environment we can check
				the appropriate dimensions at a safer time. The input nodes dimensions must be given (as a composite
				lifted type) and the other dimensions are automatically infered. If no dimensions fit the constraints,
				an exception is thrown during staging.</p>
			<h1 id="conclusion" class="unnumbered">Conclusion</h1>
			<p>LMS is a powerful meta-programming library that unlocks a wide range of possibilities and among them
				<strong>abstraction without regret</strong>. Our case study of LMS applied to computation graphs is a
				good showcase of the performance benefits of that approach while keeping a high degree of abstraction.
				Eventually, meta-programs might shape a large part of high-performance computing. By enhancing the tools
				and making the syntax seamless to the user, we hope to see the usage of LMS democratize to a wider range
				of applications.</p>
			<h1 id="references" class="unnumbered">References</h1>
			<ul>
				<li>Tiark’s thesis: <em><a
							href="https://infoscience.epfl.ch/record/180642/files/EPFL_TH5456.pdf">Lightweight Modular
							Staging and Embedded Compilers: Abstraction without Regret for High-Level High-Performance
							Programming</a></em></li>
				<li><em><a href="https://colah.github.io/posts/2015-08-Backprop/">Calculus on Computational Graphs:
							Backpropagation</a></em></li>
				<li><em><a href="http://ppl.stanford.edu/papers/gpce13-sujeeth.pdf">Forge: Generating a High Performance
							DSL Implementation from a Declarative Specification</a></em> Arvind K. Sujeeth, Austin
					Gibbons, Kevin J. Brown, HyoukJoong Lee, Tiark Rompf, Martin Odersky, and Kunle Olukotun</li>
				<li><em><a href="http://ppl.stanford.edu/papers/ecoop13_sujeeth.pdf">Composition and Reuse with Compiled
							Domain-Specific Languages</a></em> Arvind K. Sujeeth, Tiark Rompf, Kevin J. Brown,
					HyoukJoong Lee, Hassan Chafi, Victoria Popic, Michael Wu, Aleksander Prokopec, Vojin Jovanovic,
					Martin Odersky, and Kunle Olukotun</li>
				<li><em><a href="http://ppl.stanford.edu/papers/popl13_rompf.pdf">Optimizing Data Structures in
							High-Level Programs: New Directions for Extensible Compilers based on Staging</a></em> Tiark
					Rompf, Arvind K. Sujeeth, Nada Amin, Kevin J. Brown, Vojin Jovanovic, HyoukJoong Lee, Manohar
					Jonnalagedda, Kunle Olukotun, Martin Odersky</li>
				<li><em><a href="http://ppl.stanford.edu/papers/pact11-brown.pdf">A Heterogeneous Parallel Framework for
							Domain-Specific Languages</a></em> Kevin J. Brown, Arvind K. Sujeeth, HyoukJoong Lee, Tiark
					Rompf, Hassan Chafi, Martin Odersky, Kunle Olukotun</li>
			</ul>
			<h1 id="acknowledgement" class="unnumbered">Acknowledgement</h1>
			<p>Thanks to my beloved parents for their continuous support, my awesome supervisor Nada Amin, Prof. Martin
				Odersky, the LMS master and author Tiark Rompf, and the delite folks Kevin James Brown and David
				Koeplinger.</p>
			<div id="refs" class="references">

			</div>
		</div>
		<div class="license" style="margin-left:80%;">
			<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Licence Creative Commons"
					style="border-width:0" src="../../images/cc.png" /></a>
		</div>
	</div>

	<hr>

	<div id="footer">
		<section class="social">
			<a href="https://ch.linkedin.com/in/rubenfiszel" target="_blank"><i class="fa fa-linkedin fa-2x"></i></a>
			<a href="https://github.com/rubenfiszel" target="_blank"><i class="fa fa-github fa-2x"></i></a>
			<a href="mailto:ruben@rubenfiszel.com"><i class="fa fa-envelope fa-2x"></i></a>
			<a href="assets/RubenFiszel_resume.pdf"><i class="fa fa-file fa-2x"></i></a>
		</section>
	</div>

	<script src="../../js/mermaid.min.js"></script>
	<script>mermaid.initialize({ startOnLoad: true });</script>

	<script>
		(function (i, s, o, g, r, a, m) {
			i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
				(i[r].q = i[r].q || []).push(arguments)
			}, i[r].l = 1 * new Date(); a = s.createElement(o),
				m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
		})(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

		ga('create', 'UA-3040887-4', 'auto');
		ga('send', 'pageview');

	</script>
</body>

</html>
